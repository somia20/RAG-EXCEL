{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97HOXTaWvNoJ",
        "outputId": "acb51d13-efb6-43bd-86c4-0c9c03351926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmy3VJ08vXaJ",
        "outputId": "833aa7c4-42fd-4d60-d220-1ed7eb441ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.29)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.34)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.33)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlxBWEMLvfS5",
        "outputId": "3fb92918-74db-41ba-d9a8-35233061c429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stDlw3urwApx",
        "outputId": "a7d89027-3d74-4548-95a4-bac11eeeb1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.0-cp310-none-manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.0 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.0 pymupdf-1.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QA.py\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import google.generativeai as palm\n",
        "\n",
        "def create_vector_storage(pdf_path, model_name):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    data = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=40,\n",
        "        is_separator_regex=False\n",
        "    )\n",
        "    splits = text_splitter.split_documents(data)\n",
        "    embd = SentenceTransformerEmbeddings(model_name=model_name)\n",
        "    db = FAISS.from_documents(splits, embd)\n",
        "    db.save_local(\"faiss_index\")\n",
        "\n",
        "def load_vector_storage(model_name, allow_dangerous_deserialization=False):\n",
        "    embd = SentenceTransformerEmbeddings(model_name=model_name)\n",
        "    return FAISS.load_local(\"faiss_index\", embd , allow_dangerous_deserialization=allow_dangerous_deserialization)\n",
        "\n",
        "def answer_question(pdf_path, question, google_api_key):\n",
        "    # Load or create vector storage\n",
        "    model_name = \"all-MiniLM-L6-v2\"\n",
        "    if not os.path.exists(\"faiss_index\"):\n",
        "        create_vector_storage(pdf_path, model_name)\n",
        "    db = load_vector_storage(model_name, allow_dangerous_deserialization=True)\n",
        "\n",
        "    # Configure Google API\n",
        "    palm.configure(api_key=google_api_key)\n",
        "\n",
        "    # Define the query\n",
        "    query = question\n",
        "\n",
        "    # Integrate retriever\n",
        "    retriever = db.as_retriever()\n",
        "    try:\n",
        "        docs = retriever.invoke(query)\n",
        "        if docs:\n",
        "            print(\"Documents retrieved successfully\")\n",
        "        else:\n",
        "            print(\"No documents retrieved for the query.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while retrieving documents:\", e)\n",
        "\n",
        "    # Generate the answer\n",
        "    completion = palm.generate_text(\n",
        "        model='models/text-bison-001',\n",
        "        prompt=query,\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    return completion.result\n",
        "\n",
        "def main(google_api_key):\n",
        "    # Specify the path to your PDF file\n",
        "    pdf_path = \"/content/AI.pdf\"\n",
        "\n",
        "    # Example question\n",
        "    question = \"AI Vs Robotics?\"\n",
        "\n",
        "    # Call answer_question function with the provided API key\n",
        "    answer = answer_question(pdf_path, question, google_api_key)\n",
        "    print(\"Answer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Manually specify the Google API key\n",
        "    google_api_key = \"AIzaSyCKxuydsJzA--3Tgk6X1s73YRFy8tDCnH8\"\n",
        "    main(google_api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "XSm_CY7lvBRb",
        "outputId": "9f6445bf-cab4-4227-b87a-727ebcdaaeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents retrieved successfully\n",
            "Answer: AI and robotics are two closely related fields that are rapidly evolving. Both AI and robotics are concerned with the creation of intelligent machines, but there are some key differences between the two.\n",
            "\n",
            "**AI** is the study of intelligence and the creation of intelligent agents, which are systems that can reason, learn, and act autonomously. AI can be used to create a wide variety of applications, from self-driving cars to medical diagnosis tools.\n",
            "\n",
            "**Robotics** is the science of designing, building, and programming robots. Robots are machines that can be programmed to perform a variety of tasks, from simple tasks like moving objects to more complex tasks like interacting with humans.\n",
            "\n",
            "**AI and robotics are often used together** to create intelligent robots that can perform a variety of tasks autonomously. For example, AI can be used to give robots the ability to learn and adapt to their environment, while robotics can be used to give robots the physical capabilities to perform tasks in the real world.\n",
            "\n",
            "**Here are some of the key differences between AI and robotics:**\n",
            "\n",
            "* **AI is a field of study, while robotics is a field of engineering.** AI researchers are concerned with developing the theoretical foundations of intelligence, while robotics engineers are concerned with building robots that can actually perform tasks in the real world.\n",
            "* **AI is concerned with the creation of intelligent agents, while robotics is concerned with the creation of robots.** An intelligent agent is a system that can reason, learn, and act autonomously, while a robot is a machine that can be programmed to perform a variety of tasks.\n",
            "* **AI can be used to create a wide variety of applications, while robotics is more limited in its applications.** AI can be used to create everything from self-driving cars to medical diagnosis tools, while robots are typically used for more specific tasks, such as manufacturing or assembly.\n",
            "\n",
            "**AI and robotics are both rapidly evolving fields, and there is a great deal of overlap between the two.** As AI and robotics continue to develop, we can expect to see even more intelligent and capable robots being created.\n",
            "\n",
            "**Here are some of the potential benefits of AI and robotics:**\n",
            "\n",
            "* **AI and robotics can help us to solve some of the world's most pressing problems.** For example, AI and robotics can be used to develop new medical treatments, create more efficient manufacturing processes, and even help us to fight climate change.\n",
            "* **AI and robotics can make our lives easier.** AI and robotics can be used to automate tasks that are currently done by humans, freeing up our time for more creative and fulfilling activities.\n",
            "* **AI and robotics can help us to connect with the world around us.** AI and robotics can be used to create new forms of communication and interaction, allowing us to connect with people and things in new ways.\n",
            "\n",
            "**Of course, there are also some potential risks associated with AI and robotics.** For example, AI and robotics could be used to create autonomous weapons systems that could kill without human intervention. Additionally, AI and robotics could be used to create systems that are biased against certain groups of people.\n",
            "\n",
            "**It is important to weigh the potential benefits and risks of AI and robotics carefully.** With careful planning and development, AI and robotics can be used to create a better future for all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56eyqP9PzNkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import google.generativeai as palm\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_path = \"/content/kpi.csv\"\n",
        "\n",
        "def create_vector_storage(csv_path, model_name):\n",
        "    loader = CSVLoader(file_path=csv_path)\n",
        "    data = loader.load()\n",
        "\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=40,\n",
        "        is_separator_regex=False\n",
        "    )\n",
        "    # Assuming you have a method to extract text from CSV data, replace it here\n",
        "    # splits = extract_text_from_csv(data)\n",
        "    # For demonstration purposes, I'll just pass the loaded data as is\n",
        "    splits = data\n",
        "    embd = SentenceTransformerEmbeddings(model_name=model_name)\n",
        "    db = FAISS.from_documents(splits, embd)\n",
        "    db.save_local(\"faiss_index\")\n",
        "\n",
        "\n",
        "def load_vector_storage(model_name, allow_dangerous_deserialization=False):\n",
        "    embd = SentenceTransformerEmbeddings(model_name=model_name)\n",
        "    return FAISS.load_local(\"faiss_index\", embd, allow_dangerous_deserialization=allow_dangerous_deserialization)\n",
        "\n",
        "def answer_question(csv_path, question, google_api_key):\n",
        "    # Load or create vector storage\n",
        "    model_name = \"all-MiniLM-L6-v2\"\n",
        "    if not os.path.exists(\"faiss_index\"):\n",
        "        create_vector_storage(csv_path, model_name)\n",
        "    db = load_vector_storage(model_name, allow_dangerous_deserialization=True)\n",
        "\n",
        "    # Configure Google API\n",
        "    palm.configure(api_key=google_api_key)\n",
        "\n",
        "    # Define the query\n",
        "    query = question\n",
        "\n",
        "    # Integrate retriever\n",
        "    retriever = db.as_retriever()\n",
        "    try:\n",
        "        docs = retriever.invoke(query)\n",
        "        if docs:\n",
        "            print(\"Documents retrieved successfully\")\n",
        "        else:\n",
        "            print(\"No documents retrieved for the query.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while retrieving documents:\", e)\n",
        "\n",
        "    # Generate the answer\n",
        "    completion = palm.generate_text(\n",
        "        model='models/text-bison-001',\n",
        "        prompt=query,\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    return completion.result\n",
        "\n",
        "def main(google_api_key):\n",
        "    # Example question\n",
        "    question = \"Get customers who had outgoing calls deducted from their bundle subscription in the past month. Give me the where SQL statement without explanation.\"\n",
        "\n",
        "    # Call answer_question function with the provided API key\n",
        "    answer = answer_question(csv_path, question, google_api_key)\n",
        "    print(\"Answer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Manually specify the Google API key\n",
        "    google_api_key = \"AIzaSyCKxuydsJzA--3Tgk6X1s73YRFy8tDCnH8\"\n",
        "    main(google_api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "grjCsCUKzOMf",
        "outputId": "2d1ad9df-ad2b-4846-84ed-5ac1fefe25a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents retrieved successfully\n",
            "Answer: ```sql\n",
            "SELECT customer_id\n",
            "FROM bundle_subscriptions\n",
            "WHERE bundle_subscriptions.start_date <= CURRENT_DATE - INTERVAL 1 MONTH\n",
            "AND bundle_subscriptions.end_date >= CURRENT_DATE - INTERVAL 1 MONTH\n",
            "AND bundle_subscriptions.outgoing_calls > 0;\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}